---
title: "SP24 STAT240 Take-Home Midterm"
output: html_document
---

<style>body{color:#000!important}</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=T,eval=T,warning=F,message=F)

# load in packages
library(tidyverse)
library(lubridate)
library(scales)

###
### REMEMBER TO SET YOUR WORKING DIRECTORY!!!
###
```


## Question 1


The following chunk imports in the United States Department of Agriculture (USDA) Foreign Agriculture Service (FAS) Production, Supply, and Distribution (PS&D) database, [source](https://apps.fas.usda.gov/psdonline/app/index.html#/app/home).


```{r}
# download file if doesn't exist yet
if(!file.exists("psd_alldata_csv.zip")){
  download.file("https://pages.stat.wisc.edu/~bwu62/psd_alldata_csv.zip",destfile="psd_alldata_csv.zip")
}

# read in file
psd = read_csv("psd_alldata_csv.zip")

# convert all MT units to 1000 MT (i.e. millions of tons) so everything is in same units
psd = psd %>% mutate(Value = ifelse(Unit_Description=="(MT)",Value/1000,Value),
                     Unit_Description = ifelse(Unit_Description=="(MT)","(1000 MT)",Unit_Description))

# table of units (for reference)
units = psd %>% 
  select(Commodity_Description,Attribute_Description,Unit_Description) %>% 
  distinct %>% 
  pivot_wider(names_from=Attribute_Description,values_from=Unit_Description)


###
### CHECK: psd should have 2001791 rows and 12 columns! If you do not have the right dimensions,
###        remove the above lines and try downloading manually to a different (not cloud-synced
###        directory, then importing it yourself. If you still have problems, CONTACT US!
###

dim(psd)
```

### Part 1A



Create a new data frame called `psd_tidy` by performing the following operations **IN THE ORDER SPECIFIED!**. If you do the operations out of order you WILL get errors! Write all code in the chunk provided below. Check after each step that your data frame matches what is expected by using `dim()` to get the dimensions.


> NOTE: I HIGHLY recommend reading the instructions below in the knitted HTML file instead of in this Rmd file, they're formatted to be MUCH easier to read in HTML format!


1. First, select just the `Commodity_Description`, `Country_Code`, `Country_Name`, `Market_Year`, `Attribute_Description`, and `Value`.
   - **After step 1, your data frame should have 2,001,791 rows and 6 columns.**

2. Next, pivot the data frame to a wider format so that variable names from `Attribute_Description` are spread out over multiple columns and values from `Value` are used to fill in the data frame.
   - We highly recommend adding the argument ` names_repair="universal" ` to your pivot function, which will automatically repair column names by replacing invalid characters with periods
   - **After step 2, your data frame should have 155,338 rows and 75 columns**

3. After step 2, you should have a lot more columns with specific commodity details like production, imports/exports, etc. Select just the columns `Commodity_Description`, `Country_Name`, `Market_Year`, `Production`, `Imports`, `Exports` and rename these as "commodity", "country", "year", "production", "import", "export" . In addition, please also sort rows by commodity, then country, then year.
   - **After step 3, your data frame should have 155,338 rows and 6 columns**

4. Now, remove rows where:
   - The country is in a list of countries which do not have recent data for a variety of reasons (**see chunk below for details**)
      - Hint: you may consider using the syntax ` ! x %in% y ` inside `filter()` which gives you rows where column `x` are NOT in the vector `y`, OR alternatively you can use an appropriate filtering join function such as `anti_join(x,y)` to remove the rows of data frame `x` that exist in `y`.
   - The commodity is either "Cotton", "Millet", or "Mixed Grain" as these are reported inconsistently.
   - The year is 2024, since the current year is incomplete.
   - **After step 3, your data frame should have 123,186 rows and 6 columns**

> SOLUTION

```{r}
old_countries = c("Antigua and Barbuda", "EU-15", "EU-25", "Finland", "Former Czechoslovakia", "Former Yugoslavia", "Fr.Ter.Africa-Issas", "French Polynesia", "Gaza Strip", "German Democratic Republic", "Germany, Federal Republic of", "Gibraltar", "Gilbert and Ellice Islands", "Greenland", "Guadeloupe", "Luxembourg", "Malta", "Martinique", "Puerto Rico", "Serbia and Montenegro", "St. Lucia", "Union of Soviet Socialist Repu", "Virgin Islands of the U.S.", "Yemen (Aden)", "Yemen (Sanaa)", "Yugoslavia (>05/92)")
eu_countries = c("Austria","Belgium","Bulgaria","Croatia","Cyprus","Czechia","Denmark","Estonia","Finland","France","Germany","Greece","Hungary","Ireland","Italy","Latvia","Lithuania","Luxembourg","Malta","Netherlands","Poland","Portugal","Romania","Slovakia","Slovenia","Spain","Sweden")


psd_tidy = psd %>% 
  select(-Commodity_Code,-Calendar_Year,-Month,-Attribute_ID,-Unit_ID,-Unit_Description) %>% 
  pivot_wider(names_from="Attribute_Description", values_from="Value", names_repair="universal") %>% 
  filter(! Country_Name %in% c(old_countries,eu_countries), ! Commodity_Description %in% c("Cotton","Millet","Mixed Grain"), Market_Year<2024) %>% 
  select(Country_Name, Commodity_Description, Market_Year, Total.Distribution, Production, Domestic.Consumption, Exports, Imports) %>% 
  rename(country=Country_Name, commodity=Commodity_Description, year=Market_Year, 
         total.distribution=Total.Distribution, production=Production, consumption=Domestic.Consumption, export=Exports, import=Imports) %>% 
  arrange(country, commodity, year)
```




### Part 1B



Let's explore a few columns of our `psd_tidy` data frame. Perform the following operations **in order**. Remember you should NOT overwrite `psd_tidy`, so please save your output to a new data frame called `psd_summary`.


1. Filter to keep just the last 10 years (i.e. years from 2014 to 2023, including both endpoints).

2. For each commodity and country, calculate the total sum in each of the production, import, and export columns.
   - Note: use `na.rm=TRUE` inside `sum()` to ignore any NAs
   - **After step 2, your summary data frame should have 2567 rows**
   
3. Regroup by just commodity, and find the total global production of each commodity across all countries; add this as a column with the same single value in every row.

4. Calculate the percentage that each country’s production, import, and export represent out of the total global production of each commodity (that you just calculated in step 3).
   - Multiply the ratio by 100 to get a percentage between 0% and 100%.
   - Note production percentages will sum to 100% across countries, but import and export percentages will not since they are also calculated relative to total global production.
   - If you can, please round the final value to 2 decimals using `round(x,2)` where x is the column to be rounded.


Save your output as `psd_summary`, then use it to answer the following questions.


For each question, you should print a table with 1 row for each commodity showing the country name and the percentage. Please **print the ENTIRE data frame!** Note there are only 60 commodities, so you should only need to print 60 rows, use something like `print(df,n=60)`.


1. For each commodity, which country is the largest global **producer** by percentage over the last 10 years?
2. For each commodity, which country is the largest global **importer** by percentage over the last 10 years?
3. For each commodity, which country is the largest global **exporter** by percentage over the last 10 years?

> SOLUTION

```{r}
psd_statistics = psd_tidy %>% 
  filter(year >= 2014 & year <= 2023) %>% 
  group_by(country,commodity) %>% 
  summarize(total.distribution = sum(total.distribution,is.na=T),
                                            total.production = sum(production,is.na=T),
                                            total.consumption = sum(consumption,is.na=T),
                                            total.export = sum(export,is.na=T),
                                            total.import = sum(import,is.na=T)) %>% 
  group_by(commodity) %>% 
  mutate(global.total = sum(total.distribution,is.na=T)) %>% 
  ungroup() %>% 
  mutate(total.distribution = round(total.distribution/global.total*100,2),
                       total.consumption = round(total.consumption/global.total*100,2),
                       total.production = round(total.production/global.total*100,2),
                       total.export = round(total.export/global.total*100,2),
                       total.import = round(total.import/global.total*100,2))

psd_statistics %>% 
  group_by(commodity) %>% 
  select(country,total.export) %>% 
  slice_max(total.export,n=1) %>% 
  print(n=Inf)

psd_statistics %>% 
  group_by(commodity) %>% 
  select(country,total.import) %>% 
  slice_max(total.import,n=1) %>% 
  print(n=Inf)

psd_statistics %>% 
  group_by(commodity) %>% 
  select(country,total.consumption) %>% 
  slice_max(total.consumption,n=1) %>% 
  drop_na() %>% 
  print(n=Inf)

psd_statistics %>% 
  group_by(commodity) %>% 
  select(country,total.production) %>% 
  slice_max(total.production,n=1) %>% 
  print(n=Inf)
```


### Part 1C



Again, starting with `psd_tidy` from part 1A, let's focus on a few popular commodities and visualize trends in their production over the years. Create a new data frame for each question and DO NOT modify `psd_tidy` itself.


1. Corn is one of the most popular commodities. Make a plot of corn production over time.
   - Find the top 5 countries that CURRENTLY produce the most corn (i.e. in 2023).
   - Filter rows so you only have the corn production levels for these 5 countries. Note this means you need to remove both rows of other countries AND rows of other commodities.
   - Make a line plot showing production levels vs time, using a different color for each country. (Note: production units are in millions of tonnes)

2. Repeat the above steps for Wheat, another of the most popular commodities. Note you should be able to just copy the entire code above and just change Corn to Wheat everywhere.

3. Several of the commodities include the words “Meat”, “Dairy”, or “Fresh” (these are fresh produce). For example, "Meat, Chicken" and "Poultry, Meat, Broiler" are two of the several meat commodities and "Dairy, Butter" and "Dairy, Cheese" are two of several dairy commodities.
   - Use `mutate(category = str_extract(commodity,"Meat|Dairy|Fresh"))` to create a new variable called `category` which contains either the word "Meat", "Dairy", "Fresh", or NA. Drop rows where `category` is NA.
   - Drop the NA rows in this new column
   - Re-summarize the data to show the total meat, total dairy, and total fresh produce production for each country and for each year
   - Filter rows so you only have the top 10 countries by overall production of all three categories
   - Make a bar plot comparing the levels of meat, dairy, and fresh produce production for these 10 countries, using a different facet for each category.


> You must add appropriate labels (title and axes) to all plots to earn full points. 

> SOLUTION

```{r}
psd_tidy %>% 
  filter(commodity == "Corn") %>% 
  select(country,year,production) %>% 
  group_by(country) %>% 
  mutate(total = sum(production)) %>% 
  arrange(-total) %>% 
  ungroup() %>% 
  slice_max(total,n=180) %>% 
  ggplot(aes(x=year,y=production,color=country)) + 
  geom_line() + 
  labs(title="Corn production over time", x="Year", y="Production (millions of tons)")

psd_tidy %>% 
  filter(commodity == "Wheat") %>% 
  select(country,year,production) %>% 
  group_by(country) %>% 
  mutate(total = sum(production)) %>% 
  arrange(-total) %>% 
  ungroup() %>% 
  slice_max(total,n=250) %>% 
  ggplot(aes(x=year,y=production,color=country)) + geom_line() + 
  labs(title="Wheat production over time", x="Year", y="Production (millions of tons)")

psd_tidy %>% 
  mutate(category = str_extract(commodity,"Meat|Dairy|Fresh")) %>% 
  drop_na(category) %>% 
  filter(year>=2014) %>% 
  group_by(country,category) %>% 
  summarize(production = sum(production,na.rm=T)) %>% 
  group_by(country) %>% 
  mutate(total = sum(production)) %>% 
  arrange(desc(total)) %>% 
  ungroup() %>% 
  slice_max(total,n=30) %>% 
  ggplot(aes(y=reorder(country,total),fill=category,x=production)) + # reordering is optional
  geom_col(position="dodge2") # this position argument is also optional
```





## Question 2


Question 1 was a little long and complicated, so question 2 has been intentionally made a bit simpler. There are just two parts! We will be working with a dataset that comes with the `dplyr` package. The `storms` dataset contains a subset of the NOAA Atlantic hurricane database. The data includes the positions and attributes of storms from 1975-2021. Storms from 1979 onward are measured every six hours during the lifetime of the storm. Storms in earlier years have some missing data.

More info about the dataset can be found in the help page by running ` ?storms `

```{r}
data("storms")
print(storms)
```



### Part 2A


Note the data frame has many rows per storm. The purpose of this problem is to make a data summary `storms_summary` with one row per storm with the following variables:

  - `year`: year of each storm
  - `name`: name of each storm
     - note there are many duplicate names in the dataset
     - using both year and name (almost) uniquely identifies each storm with one exception (Zeta from Dec 2005 to Jan 2006, which we just ignore for now)
  - `date`: the MEDIAN date of each storm
  - `max_category`: MAXIMUM hurricane category reached
  - `max_wind`: MAXIMUM wind speeds
  - `min_pressure`: MINIMUM air pressure (note pressure decreases as storm intensity increases)

Group by `year` and `name` to (almost) uniquely identify each storm, then calculate each summary statistic listed above.
   - Note: please drop NA values by using `na.rm=TRUE` inside `median()`, `max()`, and `min()`

> Your result should have 639 or 655 rows; some computers use an older version of "storms" hence the difference. Sort this by descending date (i.e. most recent at the top) and **print at least the first 6 rows!**

> SOLUTION


```{r}
# FALL 2024 - you do not have to know ymd(str_c(...)). You should be familiar with the group_by/summarize/ggplot code that follows.

storms_summary = storms %>% 
  mutate(date = ymd(str_c(year,'-',month,'-',day))) %>%
  group_by(year,name) %>% 
  summarize(date=median(date),
            category=max(category,na.rm=T),
            wind=max(wind,na.rm=T),
            pressure=max(pressure,na.rm=T),
            storm_diameter=max(tropicalstorm_force_diameter,na.rm=T),
            hurricane_diameter=max(hurricane_force_diameter,na.rm=T)) %>% 
  arrange(desc(date))

storms_summary[storms_summary==-Inf]=NA

print(storms_summary)
```

### Part 2B



Finally we'll do a bit more visualizing and summarizing using `storms_summary` which you just created.

1. Create the `month` variable using `mutate(month=month(date,label=T))`.

2. Make a bar plot showing the average number of storms in each month.
   - The x-axis should be Jan, Feb, ..., Dec
   - The y-axis should show the average number of storms
   - **Add descriptive axis labels and plot title**
   - **Comment on the plot, what do you notice?** Do some months have more storms than others?

3. Make a similar bar plot by again creating the month variable, but this time showing the average `max_wind` for storms in each month (again, remember to use `na.rm=TRUE`). **What do you notice?**

> SOLUTION

```{r}
# FALL 2024 - you do not have to know month(date, label = T). You should be familiar with the group_by/summarize/ggplot code that follows.

storms_summary %>% 
  mutate(month=month(date,label=T)) %>% 
  ggplot(aes(x=month))+
  geom_bar()

storms_summary %>% 
  mutate(month=month(date,label=T)) %>%
  group_by(month) %>% 
  summarize(avg_peak_wind = mean(wind)) %>%
  ggplot(aes(x=month,y=avg_peak_wind))+
  geom_col()
```

