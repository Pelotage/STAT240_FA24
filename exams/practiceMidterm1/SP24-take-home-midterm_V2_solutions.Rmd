---
title: "SP24 STAT240 Take-Home Midterm Version 2"
output: html_document
---

<style>body{color:#000!important}h2,h3{margin-top:50px}</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=T,eval=T,warning=F,message=F,error=T)

# load in packages
library(tidyverse)
library(lubridate)
library(scales)

###
### REMEMBER TO SET YOUR WORKING DIRECTORY!!!
###
```


## Important notes:

 - Question 1 is longer and more complex than question 2.

 - Remember you can use any and all notes, files, videos, and cheat sheets presented in class or found on Canvas (for the tidyverse cheat sheets, you may find them using the internet). You may also reference R documentation manuals for any function. However, you may NOT search for other help online or discuss exam materials with anyone.

 - **If we ask you to print a result, you MUST print it** or you may lose points!

 - Please **KNIT as you go along and CHECK YOUR OUTPUT to ensure there are no errors**!

 - Also make sure you do NOT delete the blank lines around section headers (e.g. the ## Question x and ### Part x lines). Deleting the extra lines may cause R to knit document sections incorrectly, and we use these sections to help navigate through your exams. If they are messed up, it could make it more likely for us to accidentally miscalculate your score.


## Question 1

This question involves cleaning and exploring a dataset from the United States Department of Agriculture (USDA) Foreign Agriculture Service (FAS) Production, Supply, and Distribution (PS&D) database, [source](https://apps.fas.usda.gov/psdonline/app/index.html#/app/home).

> Note: Parts 1B and 1C both depend on 1A since 1A has all the data cleaning, but 1B and 1C do not depend on each other. If you run into problems with 1A, do your best to write as much work as possible for 1B and 1C to earn partial credit.

```{r}
## Run this entire chunk to read in all the data and convert the units to be consistent

# download file if doesn't exist yet
if(!file.exists("psd_alldata_csv.zip")){
  download.file("https://pages.stat.wisc.edu/~bwu62/psd_alldata_csv.zip",destfile="psd_alldata_csv.zip")
}

# read in file
psd = read_csv("psd_alldata_csv.zip")

# convert all MT units to 1000 MT (i.e. millions of tons) so everything is in same units
psd = psd %>% mutate(Value = ifelse(Unit_Description=="(MT)",Value/1000,Value),
                     Unit_Description = ifelse(Unit_Description=="(MT)","(1000 MT)",Unit_Description))

# table of units (for reference)
units = psd %>% 
  select(Commodity_Description,Attribute_Description,Unit_Description) %>% 
  distinct %>% 
  pivot_wider(names_from=Attribute_Description,values_from=Unit_Description)


###
### CHECK: psd should have 2001791 rows and 12 columns! If you do not have the right dimensions,
###        remove the above lines and try downloading manually to a different (not cloud-synced)
###        directory, then importing it yourself. If you still have problems, CONTACT US!
###

dim(psd)
```




### Part 1A


Create a new data frame called `psd_tidy` by performing the following operations **IN THE ORDER SPECIFIED!**. If you do the operations out of order you WILL get errors! Write all code in the chunk provided below. Check after each step that your data frame matches what is expected by using `dim()` to get the dimensions.


> NOTE: I HIGHLY recommend reading the instructions below in the knitted HTML file instead of in this Rmd file, they're formatted to be MUCH easier to read in HTML format!


1. First, select just the `Commodity_Description`, `Country_Code`, `Country_Name`, `Market_Year`, `Attribute_Description`, and `Value`.
   - **After step 1, your data frame should have 2,001,791 rows and 6 columns.**


2. Next, pivot the data frame to a wider format so that variable names from `Attribute_Description` are spread out over multiple columns and values from `Value` are used to fill in the data frame.
   - We highly recommend adding the argument ` names_repair="universal" ` to your pivot function, which will automatically repair column names by replacing invalid characters with periods
   - **After step 2, your data frame should have 155,338 rows and 75 columns**

3. After step 2, you should have a lot more columns with specific commodity details like production, imports/exports, etc. Select just the columns `Commodity_Description`, `Country_Name`, `Market_Year`, `Production`, `Imports`, `Exports` and rename these as "commodity", "country", "year", "production", "import", "export"; also keep `Total.Distribution` and `Domestic.Consumption`, rename these to be lowercase. In addition, please also sort rows by commodity, then country, then year.
   - **After step 3, your data frame should have 155,338 rows and 8 columns**

4. Now, remove rows where:
   - The country is in a list of countries which do not have recent data for a variety of reasons (**see chunk below for details**)
      - Hint: you may consider using the syntax ` ! x %in% y ` inside `filter()` which gives you rows where column `x` are NOT in the vector `y`, OR alternatively you can use an appropriate filtering join function such as `anti_join(x,y)` to remove the rows of data frame `x` that exist in `y`.
   - The commodity is either "Cotton", "Millet", or "Mixed Grain" as these are reported inconsistently.
   - The year is 2024, since the current year is incomplete.
   - **After step 3, your data frame should have 123,186 rows and 8 columns**

```{r}
## This chunk contains the two lists of countries to remove  (feel free to use this code)

## countries that no longer exist OR started reporting data together with their parent country:
old_countries = c("Antigua and Barbuda", "EU-15", "EU-25", "Former Czechoslovakia", "Former Yugoslavia", "Fr.Ter.Africa-Issas", "French Polynesia", "Gaza Strip", "German Democratic Republic", "Germany, Federal Republic of", "Gibraltar", "Gilbert and Ellice Islands", "Greenland", "Guadeloupe", "Martinique", "Puerto Rico", "Serbia and Montenegro", "St. Lucia", "Union of Soviet Socialist Repu", "Virgin Islands of the U.S.", "Yemen (Aden)", "Yemen (Sanaa)", "Yugoslavia (>05/92)")

## countries that stopped reporting individual data and instead report as part of "European Union":
eu_countries = c("Austria","Belgium","Bulgaria","Croatia","Cyprus","Czechia","Denmark","Estonia","Finland","France","Germany","Greece","Hungary","Ireland","Italy","Latvia","Lithuania","Luxembourg","Malta","Netherlands","Poland","Portugal","Romania","Slovakia","Slovenia","Spain","Sweden")

## if you want to use a filtering join, you can use this as one of the input data frames:
countries_to_remove = tibble(
  country = c(old_countries, eu_countries)
)
```


> FINALLY: To help us check your work, **please print at least the first 6 rows of your result!** Note failure to print when asked may lose points!

> NOTE: For the rest of question 1, unless otherwise specified, always start with `psd_tidy` as your initial tidy data frame. **Do NOT overwrite `psd_tidy` with any operations in later parts**, since we will reuse it.


```{r}
psd_tidy = psd %>%
  # Step 1
  select(Commodity_Description, Country_Code, Country_Name, Market_Year, Attribute_Description, Value) %>% 
  # Step 2
  pivot_wider(names_from = Attribute_Description, values_from = Value, names_repair = "universal") %>% 
  # Step 3
  select(Country_Name, Commodity_Description, Market_Year, Total.Distribution, Production, Domestic.Consumption, Exports, Imports) %>% 
  rename(country=Country_Name, commodity=Commodity_Description, year=Market_Year, 
         total.distribution=Total.Distribution, production=Production, consumption=Domestic.Consumption, export=Exports, import=Imports) %>% 
  arrange(country, commodity, year) %>% 
  # Step 4
  filter(!(country %in% eu_countries) & !(country %in% old_countries) & !(commodity %in% c("Cotton", "Millet", "Mixed Grain")) & year != 2024)
  
print(psd_tidy, n = 6)
```



### Part 1B


Let's explore a few columns of our `psd_tidy` data frame. Perform the following operations **in order**. Remember you should NOT overwrite `psd_tidy`, so please save your output to a new data frame called `psd_summary`.


1. Filter to keep just the last 10 years (i.e. years from 2014 to 2023, including both endpoints).

2. For each commodity and country, `summarize` to obtain the total sum in each of the total.distribution, production, import, and export columns.
   - Note: use `na.rm=TRUE` inside `sum()` to ignore any NAs
   - **After step 2, your summary data frame should have 2567 rows, one for each commodity-country combination.**
   
3. Regroup by just commodity. Add a new column called `global.total` that has, on each row *within a commodity*, the same value, representing the sum of the total.distribution sum you calculated in step 2.

4. Calculate the percentage that each country’s production, import, and export (the sums in step 2) represent out of the `global.total` of each commodity (that you just calculated in step 3).
    - Do this **on each country-commodity row**, do not summarize.

   - Multiply the ratio by 100 to get a percentage between 0% and 100%.
   - Note production percentages will sum to 100% across countries, but import and export percentages will not since they are also calculated relative to total global production.
   - If you can, please round the final value to 2 decimals using `round(x,2)` where x is the column to be rounded.


Save your output as `psd_summary`, then use it to answer the following questions.

```{r}
psd_summary = psd_tidy %>% 
  # Step 1
  filter(year >= 2014 & year <= 2023) %>% 
  # Step 2
  group_by(commodity, country) %>% 
  summarize(
    total.distribution = sum(total.distribution, na.rm = T),
            total.production = sum(production, na.rm = T),
            total.import = sum(import, na.rm = T),
            total.export = sum(export, na.rm = T)) %>% 
  # Step 3
  group_by(commodity) %>% 
  mutate(global.total = sum(total.distribution, na.rm = T))  %>% 
  # Step 4
  mutate(
    production_perc = (total.production/global.total * 100) %>% round(2),
    import_perc = (total.import/global.total * 100) %>% round(2),
    export_perc = (total.export/global.total * 100) %>% round(2)
  )
  
```


For each question, you should print a table with 1 row for each commodity showing the country name and the percentage. Please **print the ENTIRE data frame!** Note there are only 60 commodities, so you should only need to print 60 rows, use something like `print(df,n=60)`.


1. For each commodity, which country is the largest global **producer** by percentage over the last 10 years?

```{r}
psd_summary %>% 
  group_by(commodity) %>% 
  slice_max(production_perc, n = 1) %>% 
  select(commodity, country, production_perc) %>% 
  print(n = 60)
```


2. For each commodity, which country is the largest global **importer** by percentage over the last 10 years?

```{r}
psd_summary %>% 
  group_by(commodity) %>% 
  slice_max(import_perc, n = 1) %>%
  select(commodity, country, import_perc) %>% 
  print(n = 60)
```


3. For each commodity, which country is the largest global **exporter** by percentage over the last 10 years?


```{r}
psd_summary %>% 
  group_by(commodity) %>% 
  slice_max(export_perc, n = 1) %>% 
  select(commodity, country, export_perc) %>% 
  print(n = 60)



```




### Part 1C


Again, starting with `psd_tidy` from part 1A, let's focus on a few popular commodities and visualize trends in their production over the years. Create a new data frame for each question and DO NOT modify `psd_tidy` itself.

1. Corn is one of the most popular commodities. Make a plot of corn production over time.
   - Find the top 5 countries that produced the most corn in 2023.
   - Filter rows so you only have the corn production levels for these 5 countries. Note this means you need to remove both rows of other countries AND rows of other commodities.
   - Make a line plot showing production levels vs time, using a different color for each country. (Note: production units are in millions of tonnes)
   
```{r}
top5_Corn = psd_tidy %>% 
  filter(commodity == "Corn", year == 2023) %>% 
  slice_max(production, n = 5) %>% 
  pull(country)

top5_Corn

psd_tidy %>% 
  filter(country %in% top5_Corn, commodity == "Corn") %>% 
  ggplot(aes(year, production, color = country)) +
  geom_line() +
  labs(
    x = "Year",
    y = "Production (Millions of Tons)",
    color = "Country"
  )
```


2. Repeat the above steps for Wheat, another of the most popular commodities. Note you should be able to just copy the entire code above and just change Corn to Wheat everywhere.

```{r}
top5_Wheat = psd_tidy %>% 
  filter(commodity == "Wheat", year == 2023) %>% 
  slice_max(production, n = 5) %>% 
  pull(country)

top5_Wheat

psd_tidy %>% 
  filter(country %in% top5_Wheat, commodity == "Wheat") %>% 
  ggplot(aes(year, production, color = country)) +
  geom_line() +
  labs(
    x = "Year",
    y = "Production (Millions of Tons)",
    color = "Country"
  )
```


3. Several of the commodities include the words “Meat”, “Dairy”, or “Fresh” (these are fresh produce). For example, "Meat, Chicken" and "Poultry, Meat, Broiler" are two of the several meat commodities and "Dairy, Butter" and "Dairy, Cheese" are two of several dairy commodities.

Step 1:
   - Use `mutate(category = str_extract(commodity,"Meat|Dairy|Fresh"))` to create a new variable called `category` which contains either the word "Meat", "Dairy", "Fresh", or NA. 
   - Drop the NA rows in `category`
   
Step 2:
   - Re-summarize the data to obtain total production within each country-category combination.
   
Step 3:
   - Calculate each country's total production across all three categories, and add this as a new column, with the same value in every row within a country.
   
   - Keep the 30 rows where that country total production value is highest - this will effectively keep the top 10 countries by total production across all commodities, without getting rid of the commodity by commodity information. (*You may need to `ungroup()` first!*)

Step 4: 
Make a bar plot comparing the levels of meat, dairy, and fresh produce production for these 10 countries; put `country` on the y axis, total production on the x axis, and change the *interior* color of the bars by `category`.


> You must add appropriate labels (title and axes) to all plots to earn full points. 


```{r}
# insert code below
psd_tidy %>% 
  # Step 1
  mutate(category = str_extract(commodity,"Meat|Dairy|Fresh")) %>% 
  drop_na(category) %>% 
  # Step 2
  group_by(country, category) %>% 
  summarize(total.production = sum(production, na.rm = T)) %>% 
  # Step 3
  group_by(country) %>% 
  mutate(country.production = sum(total.production)) %>% 
  ungroup() %>% 
  slice_max(country.production, n = 30) %>% 
  # Step 4
  ggplot(aes(total.production, country, fill = category)) +
  geom_col() +
  labs(
    title = "Top 10 Countries' Dairy, Fresh, Meat Production",
    y = "Country",
    x = "Production (Millions of Tons)",
    fill = "Category"
  )

```





## Question 2


Question 1 was a little long and complicated, so question 2 has been intentionally made a bit simpler. There are just two parts! We will be working with a dataset that comes with the `dplyr` package. The `storms` dataset contains a subset of the NOAA Atlantic hurricane database. The data includes the positions and attributes of storms from 1975-2021. Storms from 1979 onward are measured every six hours during the lifetime of the storm. Storms in earlier years have some missing data.

More info about the dataset can be found in the help page by running ` ?storms `

```{r}
data("storms")
print(storms)
```



### Part 2A

Note the data frame has many rows per storm. The purpose of this problem is to make a data summary `storms_summary` with one row per storm with the following variables:

  - `year`: year of each storm
  - `name`: name of each storm
     - note there are many duplicate names in the dataset
     - using both year and name (almost) uniquely identifies each storm with one exception (Zeta from Dec 2005 to Jan 2006, which we just ignore for now)
  - `date`: the MEDIAN date of each storm
  - `max_category`: MAXIMUM hurricane category reached
  - `max_wind`: MAXIMUM wind speeds
  - `min_pressure`: MINIMUM air pressure (note pressure decreases as storm intensity increases)

Group by `year` and `name` to (almost) uniquely identify each storm, then calculate each summary statistic listed above.
   - Note: please drop NA values by using `na.rm=TRUE` inside `median()`, `max()`, and `min()`
   
Finally, sort by descending date.

> Your result should have 639 or 655 rows; some computers use an older version of "storms" hence the difference. **Print at least the first 6 rows!**


```{r}
# We give you this date variable
storms_summary = storms %>% mutate(date = ymd(str_c(year,'-',month,'-',day))) %>% 

# Write your code to overwrite storms_summary HERE; you can even continue with a pipe from the previous line if you want
group_by(year, name) %>% 
  summarize(date = median(date, na.rm = T),
            max_category = max(category, na.rm=T),
            max_wind = max(wind, na.rm = T),
            min_pressure = min(pressure, na.rm = T)) %>% 
  arrange(desc(date))


# Don't change this line, and it must be after your code above
storms_summary[storms_summary==-Inf]=NA

# Print the first 6 rows here
print(storms_summary, n = 6)
```

### Part 2B


Finally we'll do a bit more visualizing and summarizing using `storms_summary` which you just created.

1. Create the `month` variable using `mutate(month=month(date,label=T))`.

2. Make a bar plot showing the number of storms in each month.
   - The x-axis should be Jan, Feb, ..., Dec
   - The y-axis should show the number of storms
   - **Add descriptive axis labels and plot title**
   - **Comment on the plot, what do you notice?** Do some months have more storms than others?
   
```{r}
# insert code below

storms_summary %>% 
  mutate(month=month(date,label=T)) %>% 
  ggplot(aes(month)) +
  geom_bar() +
  labs(
    x = "Month",
    y = "Number of Storms"
  )

```

> Storms seem to follow a bell curve, peaking in September.


3. Make a similar bar plot by again creating the month variable, but this time showing the average `max_wind` for storms in each month (again, remember to use `na.rm=TRUE`). **What do you notice?**

```{r}
# insert code below

storms_summary %>% 
  mutate(month=month(date,label=T)) %>%
  group_by(month) %>% 
  summarize(avg_max_wind = mean(max_wind)) %>% 
  ggplot(aes(month, avg_max_wind)) +
  geom_col() +
  labs(
    x = "Month",
    y = "Avg. Max Wind"
  )

```

> The maximum wind trend is less obvious, but it still seems to peak around September-November; if January weren't so high it would be the same trend as # of storms.




